{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08b4a39-258b-4fcb-ab0f-19a454262b53",
   "metadata": {},
   "source": [
    "1. Tokenize the sentence &quot;Data science is fun and powerful!&quot; into words.\n",
    "2. Split the text &quot;AI is amazing. It powers smart devices.&quot; into sentences.\n",
    "3. Remove punctuation from &quot;Hello!!! How are you??&quot;\n",
    "4. Remove stopwords from &quot;Data science is a growing field.&quot;\n",
    "5. Stem words &quot;running&quot;, &quot;flies&quot;, &quot;denied&quot; using Porter stemmer.\n",
    "6. Perform POS tagging on &quot;The cat sat on the mat&quot;.\n",
    "7. Extract named entities from &quot;Apple is looking at buying U.K. startup for $1 billion.&quot;\n",
    "8. Remove all numbers from &quot;I have 2 dogs and 3 cats.&quot;\n",
    "9. Create a Bag of Words for two sentences.\n",
    "10. Extract only nouns and verbs from &quot;Python automates boring stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8717c9-77d1-4e7e-9244-db78e9d7c842",
   "metadata": {},
   "source": [
    "# 1 Tokenize the sentence \"Data science is fun and powerful!\" into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "968769b2-6029-414b-a3c4-c0a17107bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b6af0c0-7c72-4e0d-bc06-5c9c30381ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:['Data', 'science', 'is', 'fun', 'and', 'powerful', '!']\n"
     ]
    }
   ],
   "source": [
    "x= \"Data science is fun and powerful!\"\n",
    "doc=nlp(x)\n",
    "tokens = [token.text for token in doc]\n",
    "print(f\"Tokens:{tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f22689-355f-4faf-8180-ca7c08b8c00b",
   "metadata": {},
   "source": [
    "# 2 Split the text &quot;AI is amazing. It powers smart devices.&quot; into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ae72900-a626-402e-ad96-bb7501a935f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:['AI is amazing.', 'It powers smart devices.']\n"
     ]
    }
   ],
   "source": [
    "x = \"AI is amazing. It powers smart devices.\"\n",
    "doc = nlp(x)\n",
    "s = [sent.text for sent in doc.sents]\n",
    "print(f\"Sentence:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f506582-80c3-4d64-b303-9d526af86ec8",
   "metadata": {},
   "source": [
    "# 3 Remove punctuation from &quot;Hello!!! How are you??&quot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac5ee045-7be1-446d-bd2e-8c208b367b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation:'Hello How are you'\n"
     ]
    }
   ],
   "source": [
    "x = \"Hello!!! How are you??\"\n",
    "doc = nlp(x)\n",
    "t = [token.text for token in doc if not token.is_punct]\n",
    "c = \" \".join(t)\n",
    "print(f\"Punctuation:'{c}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef58ab7-0c9f-42b1-b531-b675972652fd",
   "metadata": {},
   "source": [
    "# 4 Remove stopwords from &quot;Data science is a growing field.&quot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e0383cd-bebc-4ebe-9b23-fd0f34275bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords: 'Data science growing field .'\n"
     ]
    }
   ],
   "source": [
    "x = \"Data science is a growing field.\"\n",
    "doc = nlp(x)\n",
    "t = [token.text for token in doc if not token.is_stop]\n",
    "te = \" \".join(t)\n",
    "print(f\"Stopwords: '{te}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ae102-5f03-4b2b-a1e9-25e4b6002db5",
   "metadata": {},
   "source": [
    "# 5 Stem words &quot;running&quot;, &quot;flies&quot;, &quot;denied&quot; using Porter stemmer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4758b360-a74b-4e5e-b407-de11c489c5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization:['run', 'fly', 'deny']\n"
     ]
    }
   ],
   "source": [
    "x = [\"running\", \"flies\", \"denied\"]\n",
    "doc = nlp(\" \".join(x))\n",
    "l = [token.lemma_ for token in doc]\n",
    "print(f\"Lemmatization:{l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb074b4-a808-4ade-8bd4-660def53d187",
   "metadata": {},
   "source": [
    "# 6 Perform POS tagging on &quot;The cat sat on the mat&quot;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e68380cd-3602-452c-81da-421e12b378dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos tagging for each word of the doc : [('The', 'DET'), ('cat', 'NOUN'), ('sat', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('mat', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "x = \"The cat sat on the mat\"\n",
    "doc = nlp(x)\n",
    "p = [(token.text, token.pos_) for token in doc]\n",
    "print(f\"Pos tagging for each word of the doc : {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9ca42-d7d6-45b9-9d1c-d6806181f891",
   "metadata": {},
   "source": [
    "# 7 Extract named entities from \"Apple is looking at buying U.K. startup for $1 billion.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0358a24f-163d-4df7-980d-369d82c41e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]\n"
     ]
    }
   ],
   "source": [
    "x = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "doc = nlp(x)\n",
    "e = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "print(f\"Entities: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba2412-b1b9-4fde-82e3-53b69f644dd7",
   "metadata": {},
   "source": [
    "# 8 Remove all numbers from \"I have 2 dogs and 3 cats.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2aedff01-f232-43a4-805b-87c75dc6b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Remove all numbers:I have dogs and cats .'\n"
     ]
    }
   ],
   "source": [
    "x = \"I have 2 dogs and 3 cats.\"\n",
    "doc = nlp(x)\n",
    "c = [token.text for token in doc if not token.like_num]\n",
    "t = \" \".join(c)\n",
    "print(f\" Remove all numbers:{t}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2bbcb-9db0-48b9-8f26-8f1bf12ce8f1",
   "metadata": {},
   "source": [
    "# 9 Create a Bag of Words for two sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90572015-b95c-4a75-ad1c-c4d9aa98e4eb",
   "metadata": {},
   "source": [
    "# 10 Extract only nouns and verbs from \"Python automates boring stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b66dabca-66cb-4021-b0a6-43e675aca6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract only nouns and verbs: ['automates', 'stuff']\n"
     ]
    }
   ],
   "source": [
    "x = \"Python automates boring stuff.\"\n",
    "doc = nlp(x)\n",
    "n = [token.text for token in doc if token.pos_ in ['NOUN', 'VERB']]\n",
    "print(f\"Extract only nouns and verbs: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4393b-1024-4e13-8a6a-7aaf4cdb7957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0aff0a-3466-41eb-80a3-cf19113fa56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
